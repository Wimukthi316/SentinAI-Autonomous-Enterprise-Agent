# SentinAI ğŸ¤–

An autonomous AI agent project with a full-stack architecture, powered by LangChain, Google Gemini API, and Whisper AI.

## ğŸ›ï¸ System Architecture

SentinAI implements a sophisticated pipeline for autonomous agent operations:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SentinAI Architecture                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   ğŸ¤ AUDIO   â”‚â”€â”€â”€â–¶â”‚  ğŸ“ TEXT     â”‚â”€â”€â”€â–¶â”‚  ğŸ§  GEMINI   â”‚â”€â”€â”€â–¶â”‚ âš¡ ACTION â”‚ â”‚
â”‚  â”‚   (Whisper)  â”‚    â”‚  Processing  â”‚    â”‚    (LLM)     â”‚    â”‚  (Agent)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                   â”‚                   â”‚                   â”‚       â”‚
â”‚         â–¼                   â–¼                   â–¼                   â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        LangChain Orchestration                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline Flow

| Stage | Component | Technology | Description |
|-------|-----------|------------|-------------|
| 1ï¸âƒ£ **Audio Input** | `AudioProcessor` | Whisper AI | Transcribes voice commands to text with high accuracy |
| 2ï¸âƒ£ **Text Processing** | `TextProcessor` | Python | Cleans, chunks, and extracts keywords from transcribed text |
| 3ï¸âƒ£ **LLM Reasoning** | `GeminiAgent` | Google Gemini API | Processes context and generates intelligent responses |
| 4ï¸âƒ£ **Action Execution** | `BaseAgent` | LangChain | Executes tasks based on LLM decisions and returns results |

### Data Flow Example

```
User speaks: "Schedule a meeting for tomorrow at 3pm"
    â”‚
    â–¼
[Whisper AI] â”€â”€â–¶ "Schedule a meeting for tomorrow at 3pm"
    â”‚
    â–¼
[Text Processor] â”€â”€â–¶ Extracts: {action: "schedule", time: "3pm", date: "tomorrow"}
    â”‚
    â–¼
[Gemini LLM] â”€â”€â–¶ Understands intent, plans action steps
    â”‚
    â–¼
[Agent] â”€â”€â–¶ Executes calendar API, confirms booking
    â”‚
    â–¼
Response: "Meeting scheduled for January 21, 2026 at 3:00 PM"
```

## ğŸ—ï¸ Project Structure

```
SentinAI/
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ agents/                 # AI Agent logic
â”‚   â”‚   â”œâ”€â”€ base_agent.py       # Abstract base agent class
â”‚   â”‚   â””â”€â”€ gemini_agent.py     # Google Gemini-powered agent
â”‚   â”œâ”€â”€ processors/             # Data processing utilities
â”‚   â”‚   â”œâ”€â”€ audio_processor.py  # Whisper AI transcription
â”‚   â”‚   â””â”€â”€ text_processor.py   # Text manipulation utilities
â”‚   â”œâ”€â”€ api/                    # API layer
â”‚   â”‚   â””â”€â”€ routes/             # API route handlers
â”‚   â”‚       â”œâ”€â”€ health.py       # Health check endpoints
â”‚   â”‚       â””â”€â”€ agents.py       # Agent interaction endpoints
â”‚   â”œâ”€â”€ data/                   # Temporary file storage (MLOps)
â”‚   â”œâ”€â”€ models/                 # ML model weights storage (MLOps)
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ frontend/                   # Next.js Frontend
â”‚   â”œâ”€â”€ app/                    # App Router pages
â”‚   â”‚   â”œâ”€â”€ layout.tsx          # Root layout
â”‚   â”‚   â”œâ”€â”€ page.tsx            # Home page with chat interface
â”‚   â”‚   â””â”€â”€ globals.css         # Global styles
â”‚   â”œâ”€â”€ package.json            # Node.js dependencies
â”‚   â”œâ”€â”€ tailwind.config.ts      # Tailwind CSS configuration
â”‚   â””â”€â”€ tsconfig.json           # TypeScript configuration
â”œâ”€â”€ Dockerfile                  # Container configuration
â”œâ”€â”€ docker-compose.yml          # Multi-container orchestration
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Tech Stack

### Backend
- **Framework**: FastAPI (Python)
- **AI/ML Tools**:
  - ğŸ”— LangChain - AI orchestration framework
  - ğŸ’ Google Gemini API - Large language model
  - ğŸ¤ Whisper AI - Speech-to-text transcription

### Frontend
- **Framework**: Next.js 14 (App Router)
- **Language**: TypeScript
- **Styling**: Tailwind CSS

### DevOps
- **Containerization**: Docker & Docker Compose
- **MLOps**: Model versioning with `models/` directory

## ğŸ“‹ Prerequisites

- Python 3.10+
- Node.js 18+
- npm or yarn
- Docker (optional, for containerization)

## ğŸ› ï¸ Installation

### Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create .env file with your API keys
# Add GOOGLE_API_KEY=your_key_here
```

### Frontend Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install
```

## ğŸš€ Running the Application

### Option 1: Local Development

**Start Backend Server:**
```bash
cd backend
uvicorn main:app --reload
```

**Start Frontend Development Server:**
```bash
cd frontend
npm run dev
```

### Option 2: Docker

```bash
# Build and run with Docker Compose
docker-compose up --build

# Or for development mode
docker-compose --profile dev up
```

The application will be available at:
- **Frontend**: `http://localhost:3000`
- **Backend API**: `http://localhost:8000`
- **API Documentation**: `http://localhost:8000/docs`

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API information |
| GET | `/api/health` | Health check |
| GET | `/api/agents/status` | Agent status and capabilities |
| POST | `/api/agents/chat` | Send message to AI agent |

## ğŸ”§ Configuration

### Backend Environment Variables

Create a `.env` file in the `backend/` directory:

```env
GOOGLE_API_KEY=your_google_api_key_here
DEBUG=True
LOG_LEVEL=INFO
```

## ğŸ“ Development Notes

- CORS is configured to allow requests from `http://localhost:3000`
- The agents have placeholder implementations ready for Gemini API integration
- Whisper AI integration is scaffolded in `processors/audio_processor.py`
- MLOps directories (`data/`, `models/`) are tracked via `.gitkeep` files

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

MIT License - feel free to use this project for your own purposes.
